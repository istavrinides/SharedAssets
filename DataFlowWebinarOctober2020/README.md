## ETL.dbc
Contains two notebooks: 
- Structured Streaming using Event Hubs 
- Transformations 

For the Event Hub producer, you can use the prod.py file as a starting point.

Products.csv is the sample file used in the Transformations notebook.


## ML Integration.dbc
Contains 6 notebooks:
- 01 - Storage
- 02 - Basic ML
- 03 - Spark ML Pipeline
- 04 - Training and Hyper-parameter tuning
- 05 - MLFlow
- 06 - InterpretML

You can find the flights_weather.csv [here](https://onedrive.live.com/?authkey=%21AO4xF-jk2-I_Ak0&cid=9C0AF81B735E29EA&id=9C0AF81B735E29EA%2123363&parId=9C0AF81B735E29EA%21229&action=defaultclick).
