## ETL.dbc
Contains two notebooks: 
- Structured Streaming using Event Hubs 
- Transformations 

For the Event Hub producer, you can use the prod.py file as a starting point.

Products.csv is the sample file used in the Transformations notebook.


## ML Integration.dbc
Contains 6 notebooks:
- 01 - Storage
- 02 - Basic ML
- 03 - Spark ML Pipeline
- 04 - Training and Hyper-parameter tuning
- 05 - MLFlow
- 06 - InterpretML
